{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b402169",
   "metadata": {},
   "source": [
    "EfficientNet1dXS is written as a PyTorch module and can be trained using the [standard PyTorch training workflow](https://docs.pytorch.org/tutorials/beginner/basics/intro.html) or any other PyTorch-oriented methods. \n",
    "\n",
    "This particular example demonstrates a general traning process within the framework of the PyTorch Lightning library. A small mock dataset is used (15 records only). \n",
    "\n",
    "For more detailed information and actual training of your own model, check out the [documentation](https://lightning.ai/docs/pytorch/stable/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c75bf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchinfo import summary\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "\n",
    "from modules.networks import EfficientNet1dXS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe09ec",
   "metadata": {},
   "source": [
    "# 1. Traning dataset\n",
    "\n",
    "Training data should be prepared using the Pytorch [Datasets and DataLoaders](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html). Here we make a mock training dataset specifically for our 4-channel time series saved in binary files. The training labels are assigned according to the file names: files \"f*\" are FRB events (class 1), all others are class 0. Note that the splitting into training and validation is simplified here: one should maintain a balance between different classes in actual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ab0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        # Instance initialization\n",
    "        self.file_list = file_list  # input file list\n",
    "\n",
    "    def __len__(self):\n",
    "        # Defining dataset length\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Reading from a binary file: file_list[idx]\n",
    "        record = np.fromfile(self.file_list[idx], dtype=np.float32)\n",
    "        record = np.reshape(record, (4, -1))  # [channels, length]\n",
    "        record = torch.tensor(record)\n",
    "        \n",
    "        # Setting a label based on the file name\n",
    "        is_frb = self.file_list[idx].stem[0] == 'f'\n",
    "        label = 1. if is_frb else 0.  # should be float for loss function\n",
    "                       \n",
    "        # Return the readout data instance and its label   \n",
    "        return record, label\n",
    "    \n",
    "    \n",
    "# File list from the \"data\" folder\n",
    "file_list = sorted(Path('data').glob('*'))\n",
    "\n",
    "# Split into train and validation (simplified)\n",
    "train, val = train_test_split(file_list, test_size=0.2, random_state=13)\n",
    "train_dataset = MockDataset(train)\n",
    "val_dataset = MockDataset(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd893a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.9084e-17,  0.0000e+00, -1.2854e+00,  ...,  2.1157e+00,\n",
       "           7.9065e-01, -7.3887e-02],\n",
       "         [-5.4010e-18, -4.6295e-18,  9.7796e-01,  ..., -2.1284e+00,\n",
       "           2.4998e-01,  2.8782e-01],\n",
       "         [-5.5152e-18, -4.4122e-18,  6.3552e-01,  ..., -1.1870e+00,\n",
       "          -1.5253e+00, -7.6169e-01],\n",
       "         [-1.1947e-17, -5.9734e-17, -5.4967e-02,  ...,  1.6960e+00,\n",
       "           1.3684e+00, -7.7276e-01]]),\n",
       " 1.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element in the training dataset: the record and its label\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53580dbb",
   "metadata": {},
   "source": [
    "# 2. Neural network\n",
    "\n",
    "Loading the neural network and checking its forward/backward pass. The number of time series at the input is 4 with a length of 4080 elements: the data shape is [4 x 4080]. The number of output classes is 1 (binary classification). The batch size = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b787b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Layer (type:depth-idx)                                  Output Shape              Param #\n",
      "=========================================================================================================\n",
      "EfficientNet1dXS                                        [2, 1]                    --\n",
      "├─Sequential: 1-1                                       [2, 640]                  --\n",
      "│    └─Conv1d: 2-1                                      [2, 12, 2040]             144\n",
      "│    └─BatchNorm1d: 2-2                                 [2, 12, 2040]             24\n",
      "│    └─GELU: 2-3                                        [2, 12, 2040]             --\n",
      "│    └─MBConv1d: 2-4                                    [2, 12, 2040]             --\n",
      "│    │    └─Identity: 3-1                               [2, 12, 2040]             --\n",
      "│    │    └─Sequential: 3-2                             [2, 12, 2040]             624\n",
      "│    └─MBConv1d: 2-5                                    [2, 24, 1020]             --\n",
      "│    │    └─Downsample1d: 3-3                           [2, 24, 1020]             336\n",
      "│    │    └─Sequential: 3-4                             [2, 24, 1020]             1,536\n",
      "│    └─MBConv1d: 2-6                                    [2, 24, 1020]             --\n",
      "│    │    └─Identity: 3-5                               [2, 24, 1020]             --\n",
      "│    │    └─Sequential: 3-6                             [2, 24, 1020]             4,752\n",
      "│    └─MBConv1d: 2-7                                    [2, 32, 510]              --\n",
      "│    │    └─Downsample1d: 3-7                           [2, 32, 510]              832\n",
      "│    │    └─Sequential: 3-8                             [2, 32, 510]              5,152\n",
      "│    └─MBConv1d: 2-8                                    [2, 32, 510]              --\n",
      "│    │    └─Identity: 3-9                               [2, 32, 510]              --\n",
      "│    │    └─Sequential: 3-10                            [2, 32, 510]              8,384\n",
      "│    └─MBConv1d: 2-9                                    [2, 64, 255]              --\n",
      "│    │    └─Downsample1d: 3-11                          [2, 64, 255]              2,176\n",
      "│    │    └─Sequential: 3-12                            [2, 64, 255]              7,300\n",
      "│    └─MBConv1d: 2-10                                   [2, 64, 255]              --\n",
      "│    │    └─Identity: 3-13                              [2, 64, 255]              --\n",
      "│    │    └─Sequential: 3-14                            [2, 64, 255]              19,592\n",
      "│    └─MBConv1d: 2-11                                   [2, 64, 255]              --\n",
      "│    │    └─Identity: 3-15                              [2, 64, 255]              --\n",
      "│    │    └─Sequential: 3-16                            [2, 64, 255]              19,592\n",
      "│    └─MBConv1d: 2-12                                   [2, 80, 255]              --\n",
      "│    │    └─Downsample1d: 3-17                          [2, 80, 255]              5,280\n",
      "│    │    └─Sequential: 3-18                            [2, 80, 255]              33,964\n",
      "│    └─MBConv1d: 2-13                                   [2, 80, 255]              --\n",
      "│    │    └─Identity: 3-19                              [2, 80, 255]              --\n",
      "│    │    └─Sequential: 3-20                            [2, 80, 255]              47,695\n",
      "│    └─MBConv1d: 2-14                                   [2, 80, 255]              --\n",
      "│    │    └─Identity: 3-21                              [2, 80, 255]              --\n",
      "│    │    └─Sequential: 3-22                            [2, 80, 255]              47,695\n",
      "│    └─MBConv1d: 2-15                                   [2, 80, 255]              --\n",
      "│    │    └─Identity: 3-23                              [2, 80, 255]              --\n",
      "│    │    └─Sequential: 3-24                            [2, 80, 255]              47,695\n",
      "│    └─MBConv1d: 2-16                                   [2, 128, 128]             --\n",
      "│    │    └─Downsample1d: 3-25                          [2, 128, 128]             10,496\n",
      "│    │    └─Sequential: 3-26                            [2, 128, 128]             59,311\n",
      "│    └─MBConv1d: 2-17                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-27                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-28                            [2, 128, 128]             120,088\n",
      "│    └─MBConv1d: 2-18                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-29                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-30                            [2, 128, 128]             120,088\n",
      "│    └─MBConv1d: 2-19                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-31                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-32                            [2, 128, 128]             120,088\n",
      "│    └─MBConv1d: 2-20                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-33                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-34                            [2, 128, 128]             120,088\n",
      "│    └─MBConv1d: 2-21                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-35                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-36                            [2, 128, 128]             120,088\n",
      "│    └─MBConv1d: 2-22                                   [2, 128, 128]             --\n",
      "│    │    └─Identity: 3-37                              [2, 128, 128]             --\n",
      "│    │    └─Sequential: 3-38                            [2, 128, 128]             120,088\n",
      "│    └─Conv1d: 2-23                                     [2, 640, 128]             81,920\n",
      "│    └─AdaptiveAvgPool1d: 2-24                          [2, 640, 1]               --\n",
      "│    └─Flatten: 2-25                                    [2, 640]                  --\n",
      "├─Sequential: 1-2                                       [2, 1]                    --\n",
      "│    └─Dropout: 2-26                                    [2, 640]                  --\n",
      "│    └─Linear: 2-27                                     [2, 1]                    641\n",
      "=========================================================================================================\n",
      "Total params: 1,125,669\n",
      "Trainable params: 1,125,669\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 323.92\n",
      "=========================================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 63.81\n",
      "Params size (MB): 4.50\n",
      "Estimated Total Size (MB): 68.44\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet1dXS(inchan=4, out_classes=1)\n",
    "\n",
    "# Check for batch size = 2. CPU is used; for GPU: device='cuda'\n",
    "print(summary(model, input_size=(2, 4, 4080), device='cpu'))\n",
    "\n",
    "# Clear memory\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4bff45",
   "metadata": {},
   "source": [
    "# 3. Training with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916372af",
   "metadata": {},
   "source": [
    "Below, a Pytorch Lightning module contains all necessary functions to performs the traning:\n",
    "* initialization\n",
    "* network forward pass\n",
    "* training step with calculation of the training loss\n",
    "* setting an optimizer and a learning rate scheduler (the latter is optional)\n",
    "* validation step with calculation of the validation loss\n",
    "* training data loader\n",
    "* validation data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda0fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning module\n",
    "class FRB_Lightning(pl.LightningModule):\n",
    "    def __init__(self, model, batch_size, lr, train_dataset, val_dataset):\n",
    "        super(FRB_Lightning, self).__init__()\n",
    "        self.save_hyperparameters(ignore='model')  # for checkpoints\n",
    "        self.model = model                  # model (neural network)\n",
    "        self.batch_size = batch_size        # batch size\n",
    "        self.lr = lr                        # learning rate\n",
    "        self.train_dataset = train_dataset  # training dataset\n",
    "        self.val_dataset = val_dataset      # validation dataset\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()  # loss function\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        records, labels = batch\n",
    "        out = self.forward(records)\n",
    "        out = torch.flatten(out) # batch flattening (binary classification)\n",
    "        loss = self.criterion(out, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Optimizer and learning rate scheduler\n",
    "        opt = torch.optim.Adamax(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=10)\n",
    "        return [opt], [scheduler]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        records, labels = batch\n",
    "        out = self.forward(records)\n",
    "        out = torch.flatten(out)  # batch flattening (binary classification)\n",
    "        loss = self.criterion(out, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=os.cpu_count(),\n",
    "            drop_last=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd3a10",
   "metadata": {},
   "source": [
    "We now create an instance of the PyTorch Lightning module and assign a value to be monitored to save the best models (checkpoints), here this is the minimum of the validation loss. An instance of PyTorch Lightning Trainer is then created with the number of epochs, logging frequency, and callbacks. Finally, the model is trained. The best models are saved in the 'lightning_logs' folder. Logs of the training can be viewed in a browser via TensorBoard: \n",
    "\n",
    "<tt>tensorboard --logdir=lightning_logs</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f239cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning module\n",
    "pl_model = FRB_Lightning(\n",
    "    EfficientNet1dXS(inchan=4, out_classes=1), \n",
    "    batch_size=2, lr=0.002, \n",
    "    train_dataset=train_dataset, \n",
    "    val_dataset=val_dataset)\n",
    "\n",
    "# Checkpoint saving based on the val_loss minimum \n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', mode='min')\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    log_every_n_steps=2,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        LearningRateMonitor('epoch'),\n",
    "        EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model training\n",
    "trainer.fit(pl_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85561bef",
   "metadata": {},
   "source": [
    "# 4. Loading checkpoints and saving the models\n",
    "\n",
    "The checkpoints saved in the 'lightning_logs' folder can be loaded. You may also want to save the model as a TorchScript to use further independently of PyTorch Lightning and other training dependencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60566522",
   "metadata": {},
   "source": [
    "Loading a previously saved checkpoint (put an actual file name below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc35d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = FRB_Lightning.load_from_checkpoint(\n",
    "    'lightning_logs/version_?/checkpoints/epoch=?-step=?.ckpt',\n",
    "    model=EfficientNet1dXS(inchan=4, out_classes=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c3e10",
   "metadata": {},
   "source": [
    "Saving the model for further usage in PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbf23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.to('cpu').eval()\n",
    "script = best_model.to_torchscript()\n",
    "torch.jit.save(script, 'filename.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2d374",
   "metadata": {},
   "source": [
    "Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, else CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "best_model = torch.jit.load('filename.pt').to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13909436",
   "metadata": {},
   "source": [
    "# 5. Making a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4a1b",
   "metadata": {},
   "source": [
    "Making a prediction for a record. This can predict incorrectly, as the mock data are too scarce for proper training. The data format should be same as in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a8b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No detection\n"
     ]
    }
   ],
   "source": [
    "# Reading our binary file\n",
    "record = np.fromfile('data/noise_h00_r1_s0000', dtype=np.float32)\n",
    "record = np.reshape(record, (4, -1))  # [channels, length]\n",
    "record = torch.tensor(record)\n",
    "\n",
    "# Adding the batch dimension and copying the data to the device (GPU or CPU)\n",
    "record = record.unsqueeze(0).to(device)\n",
    "\n",
    "# For our example of binary classification\n",
    "with torch.no_grad():\n",
    "    logit = best_model(record)\n",
    "    if logit > 0:\n",
    "        print('Detection')\n",
    "    else:\n",
    "        print('No detection')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
